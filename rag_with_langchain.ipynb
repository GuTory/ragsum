{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with LangChain\n",
    "\n",
    "These are my notebooks for learning from this [DataCamp](https://app.datacamp.com/learn/courses/retrieval-augmented-generation-rag-with-langchain) course.\n",
    "\n",
    "I used the Microsoft [2024 Annual Report](https://www.microsoft.com/investor/reports/ar24/download-center/) for my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\rag_report.pdf', 'page': 0, 'page_label': '1'}, page_content='  \\n  \\n \\n'),\n",
       " Document(metadata={'source': 'data\\\\rag_report.pdf', 'page': 1, 'page_label': '2'}, page_content=' \\n1 \\nDear shareholders, colleagues, customers, and partners: \\nFiscal year 2024 was a pivotal year for Microsoft. We entered our 50th year as a company and the second year of the AI \\nplatform shift. With these milestones, I’ve found myself reflecting on how Microsoft has remained a consequential company \\ndecade after decade in an industry with no franchise value. And I realize that it’s because—time and time again, when tech \\nparadigms have shifted —we have seized the opportunity to reinvent ourselves to stay relevant to our customers, our \\npartners, and our employees. And that’s what we are doing again today.  \\nMicrosoft has been a platform and tools company from the start. We were founded in 1975 with a belief in creating \\ntechnology that would enable others to create their own. And, nearly 50 years later, this belief remains at the heart of our \\nmission to empower every person and every organization on the planet to achieve more.   \\nThis year, we moved from talking about AI to helping our customers translate it into real outcomes —one person, one \\norganization, one institution, and one country at a time. We have made remarkable progress on this front across every \\nindustry. For example:  \\n• Coles is generating 1.6 billion daily AI predictions across 850 Australian stores, ensuring every shopper finds \\nwhat they need.  \\n• Unilever is performing thousands of simulations with AI in the time it would take to run tens of laboratory \\nexperiments, as it accelerates its product development.  \\n• Developers at Itaú, Brazil’s largest private bank, are coding more efficiently using our AI pair programmer, \\nGitHub Copilot.  \\n• Khan Academy is making tutoring more accessible for students and helping teachers plan more creative \\nlessons, using our small language model Phi.  \\n• Aquafarmers in Indonesia are improving their yields, thanks to an app built with the Azure OpenAI Service, as \\nwell as Azure IoT.  \\n• In Kenya, street vendors now have access to credit for the first time, thanks to M -Kopa, a social enterprise \\nusing Azure ML to do its forecasting.  \\n• And enterprise customers and their employees around the world, from Amgen and Disney, to Finastra and \\nVodafone, are using Microsoft 365 Copilot to become more creative and productive.  \\nFinancially, the year was also marked by record performance. We delivered over $245  billion in annual revenue, up \\n16 percent year-over-year, and over $109 billion in operating income, up 24 percent.  \\nGoing forward, we are focused on three priorities: First, prioritizing fundamentals, with security above all else. We launched \\nthe Secure Future Initiative (SFI) this year, bringing together every part of our organization to advance cybersecurity \\nprotection. Second, driving trustworthy AI innovation across our entire portfolio while continuing to scale our cloud business. \\nAnd, finally, managing our cost structure dynamically to generate durable, long -term operating leverage. All three priorities \\nare critical to our ability to continue thriving as a company as we raise the bar on our operational excellence, with a focus \\non continuous improvement across everything we do.  \\nAGE OF AI  \\nIf we go back 70 years to the beginning of modern computing, our industry has had two dreams: First, can computers \\nunderstand us instead of us having to understand computers? And second, as we digitize more of the world —including \\npeople, places, and things—can computers help us reason, plan, and act more effectively using all that information? Over \\nthe past year, we have had breakthroughs on both fronts.  \\nThe core underlying force behind these breakthroughs is scaling laws. Just like Moore’s Law drove the information \\nrevolution, the scaling laws of deep neural networks (DNN) and transformers are driving today’s AI revolution. Up until the \\nDNN inflection point, progress in compute was keeping up with Moore’s Law —doubling every two years. But we have now \\nstarted to see progress in AI performance double roughly every six months.  \\n  \\nThere are three capabilities coming together because of these scaling laws. First, we have a new natural user interface that \\nis multimodal. It supports speech, images, and videos —both as input and output. We have memory that retains important \\ncontext, recalling both our personal knowledge and data across devices, apps, and the web. And, finally, we have new '),\n",
       " Document(metadata={'source': 'data\\\\rag_report.pdf', 'page': 2, 'page_label': '3'}, page_content=' \\n2 \\nreasoning and planning capabilities that help us understand complex context, complete end-to-end tasks on our behalf, and \\nreduce our cognitive load.  \\nThis new world is being defined by a rich tapestry of AI agents, which can take action on our behalf, including personal \\nagents across work and life, business process agents, and cross-organizational ones. These agents will be able to work in \\nconcert as a new input to help make small businesses more productive, make multinationals more competitive, make the \\npublic sector more efficient, and improve health and education outcomes broadly.  \\nMicrosoft has built three leading platforms to help our customers maximize their opportunity in this emerging agentic era: \\nCopilot, which you can think of as the new UI for AI —the human interface for this agentic world; the Copilot stack, which \\nbrings together infrastructure, data, and app services to help customers build their own copilots and agents for their own \\nbusiness processes; and a new category of Copilot devices that are purpose -built for this new era, including the Copilot+ \\nPCs we introduced this year.  \\nOUR OPPORTUNITY  \\nThe innovation we have driven over the past year matters only if we translate it into enduring value for our customers. That’s \\nwhy, across our tech stack, we are focused on helping people and organizations realize the benefits of AI.  \\nInfrastructure  \\nThis year, we expanded our cloud and AI capacity, announcing new investments across five continents. These are long -\\nterm assets to drive new growth for the next decade and beyond, and ensure communities around the world have access \\nto the compute they need to drive economic growth in this new era.  \\nOur cloud now also offers top performance for AI training and inference and the most diverse selection of AI accelerators, \\nincluding the latest from AMD and NVIDIA, as well as our own first -party silicon, Azure Maia, which we introduced last \\nNovember.  \\nMore broadly, we continued to see sustained revenue growth from migrations as customers turn to Azure. Azure Arc is \\nhelping customers streamline their transition, as they secure, develop, and operate workloads with Azure services \\nanywhere. We have 36,000 A rc customers, up 90  percent year-over-year. And we remain the hyperscale cloud of choice \\nfor SAP and Oracle workloads.  \\nData & AI  \\nAI models are now key building blocks for every application. And with Azure AI, we are building out the app server for the \\nAI age, providing access to the most diverse selection of models to meet customers’ unique cost, latency, and design \\nconsiderations. We offer leading frontier models, thanks to our strategic partnership with OpenAI. With Phi -3, which we \\nannounced in April, we offer a family of powerful, small language models. And, with Models as a service, we provide API \\naccess to third-party models, in cluding the latest from Cohere, Meta, and Mistral. In total, we have over 60,000 Azure AI \\ncustomers, up nearly 60 percent year-over-year. This year, we also announced a partnership with G42, which will run its AI \\napplications and services on our cloud, as we collaborate to bring our latest AI technologies to the United Arab Emirates \\nand other countries.  \\nAI does not get created without data. At the data layer, we are fundamentally rethinking what it means to be an analytics \\ndatabase or an operational data store in the world of AI. Our Microsoft Intelligent Data Platform provides customers with the \\nbroadest capabilities spanning databases, analytics, business intelligence, and governance —along with seamless \\nintegration with all our AI services. And Microsoft Fabric, our AI-powered, next-generation data platform we made generally \\navailable this year, now has over 14,000 paid customers who can go from data, to insights, to action —all within the same \\nunified SaaS solution.  \\n  \\nDigital & app innovation  \\nFrom GitHub to Visual Studio, we have the most comprehensive developer tools. GitHub Copilot had a breakout year, as it \\nbecame standard issue for developers in every industry. We now have more than 1.8  million paid subscribers and over \\n77,000 enterprise customers, up 180 percent year-over-year. They are realizing productivity gains of up to 55 percent while '),\n",
       " Document(metadata={'source': 'data\\\\rag_report.pdf', 'page': 3, 'page_label': '4'}, page_content=' \\n3 \\nstaying in their flow and bringing the joy back to coding. This year, we also introduced Copilot Workspace, a Copilot -native \\ndeveloper environment, which helps any developer go from idea, to code, to software —all in natural language.  \\nWe are also integrating generative AI across Power Platform, enabling anyone to use natural language to create apps, \\nautomate workflows, or build a website. In total, we now have 48  million monthly active users of Power Platform, up \\n40 percent year-over-year.  \\nModern work  \\nMicrosoft 365 Copilot is becoming a daily habit for knowledge workers, transforming their work, workflow, and work artifacts. \\nAdoption has been faster than any other new Microsoft 365 suite. And employees at nearly 60  percent of the Fortune 500 \\nnow use Copilot to complete tasks faster, hold more effective meetings, and automate business workflows and processes. \\nIn fact, internal and external studies show as much as a 70  percent improvement in productivity using generative AI for \\nspecific work tasks. And early Microsoft 365 Copilot users were 29 percent faster in a series of general tasks like searching, \\nwriting, and summarizing.  \\nAnd we’re going further, bringing the Web plus Work plus Pages together as the new AI design system for knowledge work. \\nWith Pages, which we just announced last month, you can take any information from the web or your work and turn it into \\na multiplayer, AI-powered canvas. You can ideate with AI and then easily share what you create for collaboration with other \\npeople.  \\nAnd with Copilot Studio, customers can extend Copilot with agents and build their own agents that proactively respond to \\ndata and events from their own first - and third-party business data. To date, 50,000 organizations have used it. And, just \\nthis week, we announced new capabilities that will make it possible for customers to build autonomous agents using Copilot \\nStudio.  \\nMicrosoft Teams remains essential to how hundreds of millions of people meet, call, chat, collaborate, and do business. \\nThis year, we rolled out to all customers a new version that is up to two times faster while using 50  percent less memory. \\nAnd Teams Pre mium surpassed 3  million seats, up nearly 400  percent year -over-year, as organizations chose it for \\nadvanced features like end-to-end encryption and real-time translation.  \\nBusiness applications  \\nWe’re using this AI moment to redefine our role in business applications, too. Dynamics 365 once again took share, as \\norganizations use our AI-powered apps to transform their marketing, sales, service, finance, and supply chain functions.  \\nAnd we are expanding our total addressable market by integrating Copilot into third -party systems as well. Our new \\nDynamics 365 Contact Center infuses generative AI throughout the contact center workflow in a customer’s existing CRM.  \\nWe are also extending Copilot to specific industries, including healthcare. With DAX Copilot, more than 400 healthcare \\norganizations are increasing physician productivity and reducing burnout. On average, clinicians save more than five \\nminutes per patient encounter. And 77 percent say it also improves documentation quality.  \\n  \\nSecurity  \\nAs I mentioned earlier, security underpins every layer of our tech stack. We are doubling down on our Secure Future \\nInitiative, as we implement our principles of secure by design, secure by default, and secure operations. And we are focused \\non making continuous progress across the six pillars of the initiative: protect tenants and isolate production systems; protect \\nidentities and secrets; protect networks; protect engineering systems; monitor and detect threats; and accelerate response \\nand remediation. As part of this commitment, all Microsoft employees now have security as a “core priority,” holding each \\none of us accountable for building secure products and services.  \\nWe are continuously applying what we are learning and translating it into security innovation for our customers. A great \\nexample is Copilot for Security, which we made generally available this year. It brings together LLMs with domain -specific '),\n",
       " Document(metadata={'source': 'data\\\\rag_report.pdf', 'page': 4, 'page_label': '5'}, page_content=' \\n4 \\nskills informed by our threat intelligence and 78 trillion daily security signals to provide security teams with actionable \\ninsights.  \\nDevices & creativity  \\nThis year, we introduced an entirely new category of Windows PCs engineered to unleash the power of distributed AI across \\nthe cloud and edge. Copilot+ PCs are the fastest, most AI -ready Windows PCs ever built. They include a new system \\narchitecture designed to deliver best -in-class performance and breakthrough AI experiences. And we are working across \\nour entire ecosystem to bring these to life, including with AMD, Intel, and Qualcomm, along with our OEM partners.  \\nProfessional social network  \\nLinkedIn continues to see accelerated member growth and record engagement. We surpassed 1  billion members for the \\nfirst time this year, as we combine our unique data with this new generation of AI to transform how people learn, sell, and \\nget hired. LinkedIn Marketing Solutions continues to be a leader in B2B digital advertising, helping companies deliver the \\nright message, to the right audience, on a safe and trusted platform. And when it comes to our subscription businesses, \\nPremium signups increased 51  percent, and we are adding even more value to our members and customers with new AI \\ntools and skilling opportunities.  \\nSearch, ads, and news  \\nWith Copilot, we’re taking the first steps toward creating an AI companion, one that’s always by your side, helping you feel \\nsmarter and more supported through natural conversations. The refreshed Copilot app we introduced earlier this month \\ndelivers a more intuitive design with more digestible, speedy, and fluent answers. It now adapts to you with a warm tone \\nand a distinct style, providing not only information but encouragement, feedback, and advice as you navigate life’s everyday \\nchallenges—no matter how  big or small. And we’re adding advanced capabilities like Voice and Vision that make it both \\nmore useful and more natural.  \\nWe also continue to apply generative AI to pioneer new approaches to how people search and browse. Microsoft Bing and \\nEdge both took share again this year. And we introduced Copilot Pro, providing access to the latest models for quick answers \\nand higher-quality image creation, and access to Copilot for Microsoft 365 Personal and Family subscribers.  \\nThousands of news and entertainment publishers trust us to reach new audiences with Microsoft Start. And we are also \\nhelping advertisers increase their ROI. Copilot in Microsoft Ad Platform helps marketers create campaigns and troubleshoot \\nusing natural language.  \\n  \\nGaming  \\nWe are bringing great games to more people on more devices. With our acquisition of Activision Blizzard King, which closed \\nOctober 2023, we’ve added hundreds of millions of players to our ecosystem. We now have 20 franchises that have \\ngenerated over $1 billion in lifetime revenue—from Candy Crush, Diablo, and Halo, to Warcraft, Elder Scrolls, and Gears of \\nWar. And with Xbox cloud gaming, we continue to innovate to offer players more ways to experience the games they love—\\nwhere, when, and how they want. Finally, we brought four of our fan-favorite titles to Nintendo Switch and Sony PlayStation \\nfor the first time, as we continue to extend our content to new platforms.  \\nOUR MISSION  \\nAlthough we have made outstanding progress over the past year, we cannot take our permission to innovate —let alone \\noperate—for granted. It is something we must earn.  \\nWe always say Microsoft will do well only if the world around us does well. And that’s why we are focused on four enduring \\ncommitments. They keep us grounded, serving as a guide as we make decisions, pushing us to ask critical questions to \\nensure the technology we create benefits everyone on the planet, as well as the planet itself.  ')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredHTMLLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# For PDF-s\n",
    "loader = PyPDFLoader('data\\\\rag_report.pdf')\n",
    "\n",
    "# For HTML\n",
    "# htmlLoader = UnstructuredHTMLLoader()\n",
    "# data = loader.load()\n",
    "# print(data[0].page_content)\n",
    "\n",
    "# Loading Markdown files\n",
    "# from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# markdown_loader = UnstructuredMarkdownLoader('README.md')\n",
    "# markdown_content = markdown_loader.load()\n",
    "\n",
    "data: list[Document] = loader.load()\n",
    "\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting up the data to chunks for efficient retrieval\n",
    "\n",
    "first, I try with splitting up text, then splitting up the whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23 \\nreach small and medium organizations. ESAs are also typically authorized as LSPs and operate as resellers for our other', 'volume licensing programs. Microsoft Cloud Solution Provider is our main partner program for reselling cloud services.', 'We distribute our retail packaged products primarily through independent non-exclusive distributors, authorized replicators,', 'resellers, and retail outlets. Individual consumers obtain these products primarily through retail outlets. We distribute our', 'devices through third-party retailers. We have a network of field sales representatives and field support personnel that solicit', 'orders from distributors and resellers and provide product training and sales support.', 'Our Dynamics business solutions are also licensed to enterprises through a global network of channel partners providing \\nvertical solutions and specialized services.  \\nLICENSING OPTIONS', 'We offer options for organizations of varying sizes that want to purchase our cloud services and on -premise software. We', 'license these organizations under volume licensing agreements to allow the customer to acquire multiple licenses of', 'products and servic es instead of having to acquire separate licenses through retail channels. These volume licensing', 'programs have varying programmatic requirements and benefits to best meet the needs of our customers.', 'Software Assurance (“SA”) conveys rights to new software and upgrades for perpetual licenses released over the contract', 'period. It also provides support, tools, training, and other licensing benefits to help customers deploy and use software', 'efficiently. SA is required to be purchased with certain volume licensing agreements and is an optional purchase with others.  \\nVolume Licensing Programs  \\nEnterprise Agreement', 'Enterprise Agreements offer large organizations a manageable volume licensing program that gives them the flexibility to', 'buy cloud services and software licenses under one agreement. Enterprise Agreements are designed for medium or large', 'organizations that want to license Microsoft products and services organization-wide over a three-year period. Organizations', 'can elect to purchase perpetual licenses (covered with SA) and/or subscribe to cloud services.  \\nMicrosoft Customer Agreement', 'Microsoft Customer Agreements are simplified purchase agreements presented, accepted, and stored through a digital', 'experience. Microsoft Customer Agreements are non-expiring agreements that are designed to support all customers over \\ntime, whether purchasing through a partner or directly from Microsoft.', 'Microsoft Online Subscription Agreement  \\nMicrosoft Online Subscription Agreements are designed for small and medium organizations that want to subscribe to,', 'activate, provision, and maintain cloud services seamlessly and directly via the web. These agreements allow customers to \\nacquire monthly or annual subscriptions for cloud-based services.']\n",
      "[123, 118, 124, 125, 128, 86, 185, 121, 115, 117, 101, 119, 121, 176, 120, 116, 124, 125, 114, 189, 157, 188]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import random\n",
    "\n",
    "text: str = data[random.randint(0, len(data)-1)].page_content\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "print(chunks)\n",
    "print([len(chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now cut the PDF as a whole to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[943, 930, 973, 976, 685, 971, 985, 889, 880, 540, 887, 900, 953, 959, 435, 908, 910, 909, 982, 94, 884, 983, 964, 938, 663, 889, 932, 980, 971, 816, 884, 989, 966, 548, 978, 944, 961, 419, 519, 922, 910, 963, 978, 142, 908, 955, 961, 959, 897, 944, 879, 995, 883, 780, 974, 973, 974, 792, 915, 936, 996, 938, 907, 274, 966, 909, 960, 947, 528, 956, 995, 976, 961, 946, 230, 988, 913, 972, 957, 358, 973, 991, 958, 920, 936, 129, 947, 988, 953, 817, 962, 886, 913, 926, 908, 340, 944, 976, 877, 885, 882, 330, 884, 911, 890, 936, 962, 904, 950, 892, 347, 959, 918, 924, 948, 353, 970, 942, 929, 909, 927, 939, 857, 934, 933, 974, 948, 216, 945, 887, 691, 944, 969, 168, 923, 976, 997, 474, 909, 987, 940, 238, 993, 994, 913, 976, 930, 465, 903, 892, 927, 800, 933, 916, 919, 892, 243, 914, 968, 925, 911, 883, 369, 982, 916, 782, 885, 990, 922, 986, 616, 960, 956, 942, 963, 890, 978, 918, 947, 922, 993, 958, 139, 974, 967, 130, 971, 299, 560, 990, 982, 152, 955, 987, 504, 955, 302, 992, 977, 962, 572, 969, 989, 896, 967, 949, 973, 906, 959, 989, 528, 919, 921, 967, 916, 992, 880, 981, 950, 479, 997, 914, 881, 963, 983, 157, 950, 987, 955, 882, 598, 897, 921, 687, 980, 930, 459, 987, 971, 370, 976, 994, 605, 967, 935, 943, 978, 882, 870, 971, 939, 393, 960, 989, 119, 988, 992, 583, 985, 904, 775, 934, 937, 851, 966, 988, 960, 994, 898, 246, 966, 354, 978, 906, 878, 875, 938, 896, 935, 904, 917, 961, 405, 929, 967, 510, 987, 869, 911, 975, 966, 898, 782, 960, 938, 323, 983, 916, 960, 921, 981, 934, 111, 995, 901, 979, 90, 919, 940, 921, 832, 981, 929, 918, 942, 911, 984, 941, 307, 966, 970, 984, 959, 916, 992, 909, 957, 288, 236, 922, 964, 888, 408, 983, 928, 953, 889, 472, 449, 997, 819, 979, 984, 977, 666]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n', '\\n\\n'],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "print([len(c.page_content) for c in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\BISS\\ragsum\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "embeddings: list[list[float]] = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=[chunk.page_content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split to token chunks\n",
    "\n",
    "[Tokenizers](https://github.com/huggingface/tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\biss\\ragsum\\venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from tokenizers) (0.27.1)\n",
      "Requirement already satisfied: filelock in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\biss\\ragsum\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[[101, 7592, 1010, 2129, 2024, 2017, 1029, 102], [101, 1045, 2572, 2986, 1010, 4067, 2017, 999, 102]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "data = [\"Hello, how are you?\", \"I am fine, thank you!\"]\n",
    "\n",
    "tokenized_data = [tokenizer.encode(sentence, add_special_tokens=True) for sentence in data]\n",
    "\n",
    "print(tokenized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
