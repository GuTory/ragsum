{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with LangChain\n",
    "\n",
    "These are my notebooks for learning from this [DataCamp](https://app.datacamp.com/learn/courses/retrieval-augmented-generation-rag-with-langchain) course.\n",
    "\n",
    "I used the Microsoft [2024 Annual Report](https://www.microsoft.com/investor/reports/ar24/download-center/) for my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\rag_report.pdf', 'page': 0, 'page_label': '1'}, page_content='  \\n  \\n \\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredHTMLLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# For PDF-s\n",
    "loader = PyPDFLoader('data\\\\rag_report.pdf')\n",
    "\n",
    "# For HTML\n",
    "# htmlLoader = UnstructuredHTMLLoader()\n",
    "# data = loader.load()\n",
    "# print(data[0].page_content)\n",
    "\n",
    "data: list[Document] = loader.load()\n",
    "\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " 'cast_id_to_str',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'get_lc_namespace',\n",
       " 'id',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'metadata',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'page_content',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'type',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting the object attributes\n",
    "dir(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting up the data to chunks for efficient retrieval\n",
    "\n",
    "first, I try with splitting up text, then splitting up the whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['89 \\nINVESTOR RELATIONS  \\nInvestor Relations  \\nYou can contact Microsoft Investor Relations by calling \\ntoll-free at (800) 285 -7772 or outside the United States,', 'call (425) 706 -4400. We can be contacted between the \\nhours of 9:00 a.m. to 5:00 p.m. Pacific Time to answer \\ninvestment-oriented questions about Microsoft.', 'For access to additional financial information, visit the \\nInvestor Relations website online at:  \\nwww.microsoft.com/investor  \\nOur e-mail is msft@microsoft.com  \\nOur mailing address is:', 'Investor Relations  \\nMicrosoft Corporation  \\nOne Microsoft Way  \\nRedmond, Washington 98052-6399  \\nAttending the Annual Meeting  \\nThe 2024 Annual Shareholders Meeting will be held', 'as a virtual-only meeting. Any shareholder can join the \\nAnnual Meeting, while shareholders of record as of \\nSeptember 30 2024, will be able to vote and submit \\nquestions during the meeting.', 'Date: Tuesday, December 10, 2024  \\nTime: 8:30 a.m. Pacific Time  \\nVirtual Shareholder Meeting:  \\nwww.virtualshareholdermeeting.com/MSFT24  \\nSubmit Your Question', 'We invite you to submit any questions via the proxy voting \\nsite at www.proxyvote.com. We will include as many of \\nyour questions as possible during the Q&A session of the', 'meeting and will provide answers to questions on the \\nMicrosoft Investor Relations website under the Annual \\nMeeting page.  \\nRegistered Shareholder Services', 'Computershare, our transfer agent, can help you with a \\nvariety of shareholder related services including:  \\n• Change of address  \\n• Lost stock certificates  \\n• Transfer of stock to another person', '• Additional administrative services  \\nComputershare also administers a direct stock purchase \\nplan and a dividend reinvestment program for the \\ncompany.', 'Contact Computershare directly to find out more about \\nthese services and programs at 800 -285-7772, option 1, \\nor visit online at:  \\nhttps://www.computershare.com/Microsoft', 'You can e-mail the transfer agent at:  \\nweb.queries@computershare.com  \\nYou can also send mail to the transfer agent at:  \\nComputershare  \\nP.O. Box 505000  \\nLouisville, KY 40233-5000', 'Shareholders can sign up for electronic alerts to access \\nthe annual report and proxy statement online. The service \\ngets you the information you need faster and also gives', 'you the power and convenience of online proxy voting. To \\nsign up for this free servic e, visit the Annual Report site \\non the Investor Relations website at:', 'http://www.microsoft.com/investor/AnnualReports/default\\n.aspx  \\nEnvironmental, Social, and Governance (ESG)  \\nTo meet the expectations of our shareholder and other', 'stakeholders and to and maintain their trust, Microsoft is \\ncommitted to conducting our business in ways that are \\nprincipled, transparent, and accountable. Microsoft works', 'with our customers and partners  to help the world use \\ndigital technology to address business and societal \\nchallenges around the globe. In advancing this work and', 'our mission, Microsoft’s management benefits from the \\noversight and diverse perspectives offered by the Board \\nof Directors an d its committees, including key', 'environmental and social matters listed in the charter of \\nthe Board’s Environmental, Social, and Public Policy \\nCommittee.  \\nTo learn more about Microsoft’s corporate governance', 'and our environmental and social practices, please see \\nour reporting at Microsoft.com/transparency.']\n",
      "[161, 157, 186, 178, 190, 160, 171, 156, 196, 153, 173, 182, 172, 157, 163, 172, 164, 159, 178, 100]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import random\n",
    "\n",
    "text: str = data[random.randint(0, len(data)-1)].page_content\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "print(chunks)\n",
    "print([len(chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now cut the PDF as a whole to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[943, 930, 973, 976, 685, 971, 985, 889, 880, 540, 887, 900, 953, 959, 435, 908, 910, 909, 982, 94, 884, 983, 964, 938, 663, 889, 932, 980, 971, 816, 884, 989, 966, 548, 978, 944, 961, 419, 519, 922, 910, 963, 978, 142, 908, 955, 961, 959, 897, 944, 879, 995, 883, 780, 974, 973, 974, 792, 915, 936, 996, 938, 907, 274, 966, 909, 960, 947, 528, 956, 995, 976, 961, 946, 230, 988, 913, 972, 957, 358, 973, 991, 958, 920, 936, 129, 947, 988, 953, 817, 962, 886, 913, 926, 908, 340, 944, 976, 877, 885, 882, 330, 884, 911, 890, 936, 962, 904, 950, 892, 347, 959, 918, 924, 948, 353, 970, 942, 929, 909, 927, 939, 857, 934, 933, 974, 948, 216, 945, 887, 691, 944, 969, 168, 923, 976, 997, 474, 909, 987, 940, 238, 993, 994, 913, 976, 930, 465, 903, 892, 927, 800, 933, 916, 919, 892, 243, 914, 968, 925, 911, 883, 369, 982, 916, 782, 885, 990, 922, 986, 616, 960, 956, 942, 963, 890, 978, 918, 947, 922, 993, 958, 139, 974, 967, 130, 971, 299, 560, 990, 982, 152, 955, 987, 504, 955, 302, 992, 977, 962, 572, 969, 989, 896, 967, 949, 973, 906, 959, 989, 528, 919, 921, 967, 916, 992, 880, 981, 950, 479, 997, 914, 881, 963, 983, 157, 950, 987, 955, 882, 598, 897, 921, 687, 980, 930, 459, 987, 971, 370, 976, 994, 605, 967, 935, 943, 978, 882, 870, 971, 939, 393, 960, 989, 119, 988, 992, 583, 985, 904, 775, 934, 937, 851, 966, 988, 960, 994, 898, 246, 966, 354, 978, 906, 878, 875, 938, 896, 935, 904, 917, 961, 405, 929, 967, 510, 987, 869, 911, 975, 966, 898, 782, 960, 938, 323, 983, 916, 960, 921, 981, 934, 111, 995, 901, 979, 90, 919, 940, 921, 832, 981, 929, 918, 942, 911, 984, 941, 307, 966, 970, 984, 959, 916, 992, 909, 957, 288, 236, 922, 964, 888, 408, 983, 928, 953, 889, 472, 449, 997, 819, 979, 984, 977, 666]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "print([len(c.page_content) for c in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openaiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain_openai) (0.3.31)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
      "  Downloading openai-1.60.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.3.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\biss\\ragsum\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\biss\\ragsum\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\biss\\ragsum\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\biss\\ragsum\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\biss\\ragsum\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
      "Downloading openai-1.60.1-py3-none-any.whl (456 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/883.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 883.8/883.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain_openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 langchain_openai-0.3.2 openai-1.60.1 regex-2024.11.6 tiktoken-0.8.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "%pip install langchain_chroma\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
