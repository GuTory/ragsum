{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "from datetime import date\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "\n",
    "from utils import (\n",
    "    compute_metrics,\n",
    "    load_all_available_transcripts,\n",
    "    SummarizationPipeline,\n",
    "    TextChunker,\n",
    "    LoggingConfig,\n",
    "    ModelConfig,\n",
    "    TopicModeler,\n",
    "    Retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 19:36:38,711 - utils.loaders - INFO - 32307\n",
      "2025-05-04 19:36:38,847 - utils.loaders - INFO - Successfully loaded local transcripts for 32307\n",
      "2025-05-04 19:36:38,849 - utils.loaders - INFO - Successfully loaded 32307.csv\n",
      "2025-05-04 19:36:38,849 - utils.loaders - INFO - 126475\n",
      "2025-05-04 19:36:38,882 - utils.loaders - INFO - Successfully loaded local transcripts for 126475\n",
      "2025-05-04 19:36:38,883 - utils.loaders - INFO - Successfully loaded 126475.csv\n",
      "2025-05-04 19:36:38,884 - utils.loaders - INFO - 26446\n",
      "2025-05-04 19:36:38,900 - utils.loaders - INFO - Successfully loaded local transcripts for 26446\n",
      "2025-05-04 19:36:38,901 - utils.loaders - INFO - Successfully loaded 26446.csv\n",
      "2025-05-04 19:36:38,902 - utils.loaders - INFO - 388904\n",
      "2025-05-04 19:36:38,928 - utils.loaders - INFO - Successfully loaded local transcripts for 388904\n",
      "2025-05-04 19:36:38,929 - utils.loaders - INFO - Successfully loaded 388904.csv\n",
      "2025-05-04 19:36:38,929 - utils.loaders - INFO - 312932093\n",
      "2025-05-04 19:36:38,933 - utils.loaders - INFO - Successfully loaded local transcripts for 312932093\n",
      "2025-05-04 19:36:38,934 - utils.loaders - INFO - Successfully loaded 312932093.csv\n",
      "2025-05-04 19:36:38,936 - utils.loaders - INFO - Successfully combined all matching transcripts: (165, 9)\n"
     ]
    }
   ],
   "source": [
    "transcripts = load_all_available_transcripts()\n",
    "transcripts = transcripts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>mostimportanttimeutc</th>\n",
       "      <th>headline</th>\n",
       "      <th>full_text</th>\n",
       "      <th>uuid</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32307</td>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>15:50:00</td>\n",
       "      <td>NVIDIA Corporation Presents at J.P. MORGAN 21S...</td>\n",
       "      <td>Analysts: All right. Why don't we go ahead and...</td>\n",
       "      <td>ca419775-262e-4e3a-975a-e4ead13ef55b</td>\n",
       "      <td>9541</td>\n",
       "      <td>10911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   companyid         companyname mostimportantdateutc mostimportanttimeutc  \\\n",
       "0      32307  NVIDIA Corporation           2023-01-05             15:50:00   \n",
       "\n",
       "                                            headline  \\\n",
       "0  NVIDIA Corporation Presents at J.P. MORGAN 21S...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Analysts: All right. Why don't we go ahead and...   \n",
       "\n",
       "                                   uuid  word_count  word_count_nltk  \n",
       "0  ca419775-262e-4e3a-975a-e4ead13ef55b        9541            10911  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = transcripts['full_text'].tolist()\n",
    "metadata = transcripts[['uuid', 'companyid', 'companyname', 'word_count_nltk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [\n",
    "    'facebook/bart-large-cnn',\n",
    "    'google-t5/t5-base',\n",
    "    'google/pegasus-x-large',\n",
    "    'human-centered-summarization/financial-summarization-pegasus',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_config = LoggingConfig()\n",
    "all_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 13112/13112 [13:32<00:00, 16.13doc/s]\n",
      "Indexing: 100%|██████████| 13112/13112 [00:00<00:00, 507541.87vec/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'hf://datasets/sohomghosh/FinRAD_Financial_Readability_Assessment_Dataset/FinRAD_13K_terms_definitions_labels.csv'\n",
    ")\n",
    "df = df[['terms', 'definitions', 'source', 'assigned_readability']]\n",
    "df = df.dropna(subset=['definitions'])\n",
    "df['combined'] = df['terms'] + ': ' + df['definitions']\n",
    "\n",
    "retriever = Retriever(df.combined.tolist(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:35:30,064 - SummarizationPipeline - INFO - Initializing pipeline with model facebook/bart-large-cnn\n",
      "2025-05-04 20:35:30,065 - SummarizationPipeline - INFO - Loading tokenizer for facebook/bart-large-cnn\n",
      "2025-05-04 20:35:30,989 - SummarizationPipeline - INFO - Loading model for facebook/bart-large-cnn (8bit=False, device=cpu)\n",
      "2025-05-04 20:35:31,747 - SummarizationPipeline - INFO - Model and tokenizer loaded successfully. Model max length: 1000000000000000019884624838656\n",
      "2025-05-04 20:35:31,748 - SummarizationPipeline - INFO - Using prefix: summarize: \n",
      "2025-05-04 20:35:31,760 - SummarizationPipeline - WARNING - Model vocab size (50265) and tokenizer vocab size (50264) mismatch. Resizing model embeddings.\n",
      "2025-05-04 20:35:33,049 - utils.text_chunker - INFO - Initialized TextChunker with chunk_size=1024, chunk_overlap=102, prefix=\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce911efd677424195b21676af491223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing with facebook/bart-large-cnn:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:35:33,111 - utils.text_chunker - INFO - Starting text chunking...\n",
      "Chunking text: 100%|██████████| 13/13 [00:00<00:00, 70356.07it/s]\n",
      "2025-05-04 20:35:33,133 - utils.text_chunker - INFO - Text successfully split into 13 chunks.\n",
      "2025-05-04 20:35:33,134 - utils.text_chunker - INFO - Starting text chunking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4665, 4743, 4723, 4642, 4688, 4691, 4727, 4729, 4621, 4828, 4626, 4748, 3110]\n",
      "chunk size: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text: 100%|██████████| 76/76 [00:00<00:00, 283096.90it/s]\n",
      "2025-05-04 20:35:33,149 - utils.text_chunker - INFO - Text successfully split into 76 chunks.\n",
      "2025-05-04 20:35:33,151 - top2vec - INFO - Pre-processing documents for training\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-05-04 20:35:33,226 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1172, 1170, 1195, 1152, 1106, 1131, 1197, 1163, 1205, 1206, 1169, 1119, 1163, 1093, 1081, 1219, 1309, 1247, 1180, 1185, 1145, 1105, 1152, 1190, 1166, 1165, 1109, 1141, 1212, 1212, 1219, 1163, 1135, 1128, 1205, 1144, 1217, 1211, 1171, 1166, 1194, 1150, 1097, 1125, 1189, 1164, 1207, 1217, 1168, 1136, 1164, 1106, 1110, 1204, 1325, 1271, 1205, 1191, 1137, 1092, 1114, 1181, 1183, 1165, 1099, 1131, 1205, 1239, 1235, 1184, 1135, 1145, 1192, 1155, 1223, 893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:35:34,451 - top2vec - INFO - Creating joint document/word embedding\n",
      "2025-05-04 20:35:36,240 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 20:35:36,714 - top2vec - INFO - Finding dense areas of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 20:35:36,720 - top2vec - INFO - Finding topics\n",
      "Reducing topics: 100%|██████████| 1/1 [00:00<00:00, 459.05it/s]\n",
      "2025-05-04 20:35:36,790 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: gaming architecture market software we growth our not as do so working more about work great but ve both what and to in team really new are also is you for re see year now your well this has with the have terms be think that on very of here\n",
      "found definition: pvgo: present value of growth opportunities.\n",
      "found definition: present value of growth opportunities PVGO: Net present value of a firm™s future investments.\n",
      "found definition: Net Present Value of Growth Opportunities (NPVGO): The net present value of growth opportunities (NPVGO) is a calculation of the net present value per share of all future cash flows involved with growth opportunities such as new projects or potential acquisitions. The net present value of growth opportunities is used to determine the intrinsic value per share of these growth opportunities in order to determine how much of the firm's current per-share value is determined by them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:35:54,346 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:36:11,953 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:36:32,587 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:36:49,713 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:37:06,036 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:37:22,596 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:37:36,827 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:37:52,243 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:38:07,748 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:38:24,629 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:38:37,917 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:38:55,065 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:39:09,698 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:39:26,771 - SummarizationPipeline - INFO - Initializing pipeline with model google-t5/t5-base\n",
      "2025-05-04 20:39:26,780 - SummarizationPipeline - INFO - Loading tokenizer for google-t5/t5-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c16c68bff549e38b1f06140e060377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0f18880fca41bdb6fcd21d8f22b675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87f92d46f794b3484dc140b77200a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:39:28,745 - SummarizationPipeline - INFO - Loading model for google-t5/t5-base (8bit=False, device=cpu)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f6cf4d0edf48868bdb48c20b6168dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c594233c7c4b5abd92dc3371606183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:39:33,798 - SummarizationPipeline - INFO - Model and tokenizer loaded successfully. Model max length: 1000000000000000019884624838656\n",
      "2025-05-04 20:39:33,799 - SummarizationPipeline - INFO - Using prefix: summarize: \n",
      "2025-05-04 20:39:33,811 - SummarizationPipeline - WARNING - Model vocab size (32100) and tokenizer vocab size (32128) mismatch. Resizing model embeddings.\n",
      "2025-05-04 20:39:34,130 - utils.text_chunker - INFO - Initialized TextChunker with chunk_size=1024, chunk_overlap=102, prefix=\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9353224a740f4061ac463f96baccbbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing with google-t5/t5-base:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:39:34,158 - utils.text_chunker - INFO - Starting text chunking...\n",
      "Chunking text: 100%|██████████| 13/13 [00:00<00:00, 90424.46it/s]\n",
      "2025-05-04 20:39:34,194 - utils.text_chunker - INFO - Text successfully split into 13 chunks.\n",
      "2025-05-04 20:39:34,195 - utils.text_chunker - INFO - Starting text chunking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4665, 4743, 4723, 4642, 4688, 4691, 4727, 4729, 4621, 4828, 4626, 4748, 3110]\n",
      "chunk size: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text: 100%|██████████| 76/76 [00:00<00:00, 407630.57it/s]\n",
      "2025-05-04 20:39:34,208 - utils.text_chunker - INFO - Text successfully split into 76 chunks.\n",
      "2025-05-04 20:39:34,211 - top2vec - INFO - Pre-processing documents for training\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-05-04 20:39:34,296 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1172, 1170, 1195, 1152, 1106, 1131, 1197, 1163, 1205, 1206, 1169, 1119, 1163, 1093, 1081, 1219, 1309, 1247, 1180, 1185, 1145, 1105, 1152, 1190, 1166, 1165, 1109, 1141, 1212, 1212, 1219, 1163, 1135, 1128, 1205, 1144, 1217, 1211, 1171, 1166, 1194, 1150, 1097, 1125, 1189, 1164, 1207, 1217, 1168, 1136, 1164, 1106, 1110, 1204, 1325, 1271, 1205, 1191, 1137, 1092, 1114, 1181, 1183, 1165, 1099, 1131, 1205, 1239, 1235, 1184, 1135, 1145, 1192, 1155, 1223, 893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:39:35,489 - top2vec - INFO - Creating joint document/word embedding\n",
      "2025-05-04 20:39:37,331 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 20:39:37,804 - top2vec - INFO - Finding dense areas of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 20:39:37,810 - top2vec - INFO - Finding topics\n",
      "Reducing topics: 100%|██████████| 1/1 [00:00<00:00, 403.34it/s]\n",
      "2025-05-04 20:39:37,963 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: growth market architecture gaming we software year our not be terms as more working do is so team work are in re great about to and think both but the what very new really for see also now has this you that with ve have of your it well on\n",
      "found definition: pvgo: present value of growth opportunities.\n",
      "found definition: present value of growth opportunities PVGO: Net present value of a firm™s future investments.\n",
      "found definition: Boom and bust: See business cycle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:39:41,257 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:39:54,097 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:40:05,866 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:40:16,811 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:40:25,247 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:40:35,504 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:40:50,337 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:41:00,872 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:41:13,538 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:41:24,102 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:41:33,339 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:41:47,979 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:41:58,146 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:42:08,977 - SummarizationPipeline - INFO - Initializing pipeline with model google/pegasus-x-large\n",
      "2025-05-04 20:42:08,987 - SummarizationPipeline - INFO - Loading tokenizer for google/pegasus-x-large\n",
      "2025-05-04 20:42:08,990 - SummarizationPipeline - INFO - Using specialized PegasusTokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc9d6c8d5144cfbacf7f9c9281a9d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063c4d3348b4c35a5af1f1d1123df95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b078beda4d4a2bb42197e7866f477a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e9c673e52f483da8e136343af70b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/6.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e7170df23b42e98511b860e60fa164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type pegasus_x to instantiate a model of type pegasus. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5caa2cb8b9c4394b0d81e7c4add3019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4bcc48e2464f3dba523ab18cd8903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-x-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.12.encoder_attn.k_proj.bias', 'model.decoder.layers.12.encoder_attn.out_proj.bias', 'model.decoder.layers.12.encoder_attn.q_proj.bias', 'model.decoder.layers.12.encoder_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.13.encoder_attn.k_proj.bias', 'model.decoder.layers.13.encoder_attn.out_proj.bias', 'model.decoder.layers.13.encoder_attn.q_proj.bias', 'model.decoder.layers.13.encoder_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.14.encoder_attn.k_proj.bias', 'model.decoder.layers.14.encoder_attn.out_proj.bias', 'model.decoder.layers.14.encoder_attn.q_proj.bias', 'model.decoder.layers.14.encoder_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.15.encoder_attn.k_proj.bias', 'model.decoder.layers.15.encoder_attn.out_proj.bias', 'model.decoder.layers.15.encoder_attn.q_proj.bias', 'model.decoder.layers.15.encoder_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.12.self_attn.k_proj.bias', 'model.encoder.layers.12.self_attn.out_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.bias', 'model.encoder.layers.12.self_attn.v_proj.bias', 'model.encoder.layers.13.self_attn.k_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.q_proj.bias', 'model.encoder.layers.13.self_attn.v_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.v_proj.bias', 'model.encoder.layers.15.self_attn.k_proj.bias', 'model.encoder.layers.15.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.q_proj.bias', 'model.encoder.layers.15.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b79d14b92f4e728b332a8e7e489d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/262 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:45:02,951 - SummarizationPipeline - INFO - Model and tokenizer loaded successfully. Model max length: 1024\n",
      "2025-05-04 20:45:02,952 - SummarizationPipeline - INFO - Using prefix: \n",
      "2025-05-04 20:45:02,953 - SummarizationPipeline - INFO - Model and tokenizer vocab sizes match. No resizing needed.\n",
      "2025-05-04 20:45:02,954 - utils.text_chunker - INFO - Initialized TextChunker with chunk_size=1024, chunk_overlap=102, prefix=\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652ae21d4c0b4324ae857a81a116af12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing with google/pegasus-x-large:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:45:03,045 - utils.text_chunker - INFO - Starting text chunking...\n",
      "\n",
      "Chunking text: 100%|██████████| 13/13 [00:00<00:00, 77014.06it/s]\n",
      "2025-05-04 20:45:03,063 - utils.text_chunker - INFO - Text successfully split into 13 chunks.\n",
      "2025-05-04 20:45:03,064 - utils.text_chunker - INFO - Starting text chunking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4665, 4743, 4723, 4642, 4688, 4691, 4727, 4729, 4621, 4828, 4626, 4748, 3110]\n",
      "chunk size: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunking text: 100%|██████████| 76/76 [00:00<00:00, 377239.18it/s]\n",
      "2025-05-04 20:45:03,096 - utils.text_chunker - INFO - Text successfully split into 76 chunks.\n",
      "2025-05-04 20:45:03,099 - top2vec - INFO - Pre-processing documents for training\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-05-04 20:45:03,166 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1172, 1170, 1195, 1152, 1106, 1131, 1197, 1163, 1205, 1206, 1169, 1119, 1163, 1093, 1081, 1219, 1309, 1247, 1180, 1185, 1145, 1105, 1152, 1190, 1166, 1165, 1109, 1141, 1212, 1212, 1219, 1163, 1135, 1128, 1205, 1144, 1217, 1211, 1171, 1166, 1194, 1150, 1097, 1125, 1189, 1164, 1207, 1217, 1168, 1136, 1164, 1106, 1110, 1204, 1325, 1271, 1205, 1191, 1137, 1092, 1114, 1181, 1183, 1165, 1099, 1131, 1205, 1239, 1235, 1184, 1135, 1145, 1192, 1155, 1223, 893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:45:04,417 - top2vec - INFO - Creating joint document/word embedding\n",
      "2025-05-04 20:45:06,226 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 20:45:06,708 - top2vec - INFO - Finding dense areas of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 20:45:06,714 - top2vec - INFO - Finding topics\n",
      "\n",
      "Reducing topics: 100%|██████████| 1/1 [00:00<00:00, 461.98it/s]\n",
      "2025-05-04 20:45:06,785 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: gaming market architecture software we growth not our as do so working more about ve work both but and really team what great to in also is you are new year for see re well your now has the with terms this have be think that on very of right\n",
      "found definition: pvgo: present value of growth opportunities.\n",
      "found definition: present value of growth opportunities PVGO: Net present value of a firm™s future investments.\n",
      "found definition: Net Present Value of Growth Opportunities (NPVGO): The net present value of growth opportunities (NPVGO) is a calculation of the net present value per share of all future cash flows involved with growth opportunities such as new projects or potential acquisitions. The net present value of growth opportunities is used to determine the intrinsic value per share of these growth opportunities in order to determine how much of the firm's current per-share value is determined by them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:46:51,981 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:48:35,947 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:50:26,365 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:51:24,622 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:52:53,966 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:54:14,611 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:55:09,341 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:56:30,548 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:57:44,788 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:58:38,145 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 20:59:53,840 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:01:26,148 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:02:44,650 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "2025-05-04 21:03:48,680 - utils.text_chunker - INFO - Starting text chunking...\n",
      "Chunking text: 100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
      "2025-05-04 21:03:48,693 - utils.text_chunker - INFO - Text successfully split into 1 chunks.\n",
      "2025-05-04 21:03:48,694 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:05:31,761 - SummarizationPipeline - INFO - Initializing pipeline with model human-centered-summarization/financial-summarization-pegasus\n",
      "2025-05-04 21:05:31,762 - SummarizationPipeline - INFO - Loading tokenizer for human-centered-summarization/financial-summarization-pegasus\n",
      "2025-05-04 21:05:31,766 - SummarizationPipeline - INFO - Using specialized PegasusTokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a812da0d2d064e209f9ceafa4777ce9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490e27a40eca4d0b9509e097143bc837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9052a8628a45679af8fd926b578081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4c835c169147ad8f78d43752b7d333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d54322dc3741758d591f1d1c437d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at human-centered-summarization/financial-summarization-pegasus and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-04 21:06:30,480 - SummarizationPipeline - INFO - Model and tokenizer loaded successfully. Model max length: 512\n",
      "2025-05-04 21:06:30,482 - SummarizationPipeline - INFO - Using prefix: \n",
      "2025-05-04 21:06:30,483 - SummarizationPipeline - INFO - Model and tokenizer vocab sizes match. No resizing needed.\n",
      "2025-05-04 21:06:30,484 - utils.text_chunker - INFO - Initialized TextChunker with chunk_size=512, chunk_overlap=51, prefix=\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3880fdafc5784637bcdb4fc5bad63740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing with human-centered-summarization/financial-summarization-pegasus:   0%|          | 0/1 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:06:30,539 - utils.text_chunker - INFO - Starting text chunking...\n",
      "Chunking text: 100%|██████████| 26/26 [00:00<00:00, 129055.51it/s]\n",
      "2025-05-04 21:06:30,561 - utils.text_chunker - INFO - Text successfully split into 26 chunks.\n",
      "2025-05-04 21:06:30,562 - utils.text_chunker - INFO - Starting text chunking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400, 2295, 2411, 2355, 2242, 2449, 2336, 2274, 2290, 2358, 2360, 2314, 2404, 2307, 2307, 2412, 2348, 2266, 2530, 2321, 2318, 2290, 2442, 2282, 2334, 1007]\n",
      "chunk size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text: 100%|██████████| 152/152 [00:00<00:00, 529074.03it/s]\n",
      "2025-05-04 21:06:30,588 - utils.text_chunker - INFO - Text successfully split into 152 chunks.\n",
      "2025-05-04 21:06:30,590 - top2vec - INFO - Pre-processing documents for training\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-05-04 21:06:30,653 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[611, 641, 526, 602, 592, 603, 589, 540, 560, 570, 553, 589, 612, 592, 586, 656, 592, 604, 616, 615, 587, 564, 580, 551, 557, 626, 579, 522, 538, 563, 529, 581, 662, 647, 620, 609, 582, 568, 594, 598, 602, 567, 570, 569, 550, 590, 613, 589, 568, 596, 608, 566, 555, 543, 540, 588, 610, 627, 578, 614, 646, 609, 590, 592, 569, 540, 553, 583, 613, 603, 574, 550, 565, 644, 658, 529, 613, 628, 539, 611, 582, 608, 587, 548, 554, 556, 548, 580, 609, 589, 588, 643, 579, 591, 614, 628, 592, 579, 577, 551, 543, 631, 595, 525, 537, 562, 556, 580, 669, 650, 639, 621, 617, 590, 605, 610, 584, 565, 540, 565, 526, 582, 606, 598, 590, 601, 600, 602, 546, 592, 565, 557, 602, 621, 611, 610, 637, 641, 587, 589, 581, 547, 567, 574, 584, 602, 600, 550, 567, 594, 677, 468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:06:31,868 - top2vec - INFO - Creating joint document/word embedding\n",
      "2025-05-04 21:06:33,366 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 21:06:33,925 - top2vec - INFO - Finding dense areas of documents\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-04 21:06:33,933 - top2vec - INFO - Finding topics\n",
      "Reducing topics: 100%|██████████| 1/1 [00:00<00:00, 359.19it/s]\n",
      "2025-05-04 21:06:34,139 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: market architecture growth software we year not so our great and just working really is do as work more now in what but at about very new are team see both terms re the that has this for to also ve you think it well with be right your of\n",
      "found definition: pvgo: present value of growth opportunities.\n",
      "found definition: present value of growth opportunities PVGO: Net present value of a firm™s future investments.\n",
      "found definition: New growth theory: See GROWTH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:07:03,391 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:07:31,860 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:08:05,652 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:08:36,254 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:09:05,138 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:09:38,462 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:10:09,311 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:10:39,339 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:11:11,660 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:11:45,666 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:12:14,861 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:12:45,461 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:13:15,876 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:13:51,568 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:14:23,336 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:14:57,548 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:15:29,330 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:16:00,505 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:16:35,014 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:17:05,546 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:17:36,405 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:18:08,815 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:18:38,387 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:19:08,436 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:19:47,149 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "2025-05-04 21:20:18,941 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 512). Running this sequence through the model will result in indexing errors\n",
      "2025-05-04 21:20:49,903 - utils.text_chunker - INFO - Starting text chunking...\n",
      "Chunking text: 100%|██████████| 1/1 [00:00<00:00, 8962.19it/s]\n",
      "2025-05-04 21:20:49,913 - utils.text_chunker - INFO - Text successfully split into 1 chunks.\n",
      "2025-05-04 21:20:49,913 - SummarizationPipeline - INFO - Generating summary (max_new_tokens=100)\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    model_config = ModelConfig(\n",
    "        model_name_or_path=checkpoint,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    pipeline = SummarizationPipeline(\n",
    "        model_config=model_config,\n",
    "        logging_config=logging_config,\n",
    "        remote=True\n",
    "    )\n",
    "    tokenizer = pipeline.get_tokenizer()\n",
    "    chunker = TextChunker(tokenizer)\n",
    "\n",
    "    summaries = []\n",
    "    for text in tqdm(original_texts, desc=f\"Summarizing with {checkpoint}\"):\n",
    "        chunks = chunker.chunk_text(text)\n",
    "\n",
    "        print([len(x) for x in chunks])\n",
    "\n",
    "        chunker.resize_chunks(int(chunker._adjusted_chunk_size / 4))\n",
    "\n",
    "        print(f'chunk size: {chunker._adjusted_chunk_size}')\n",
    "\n",
    "        tm_chunks = chunker.chunk_text(text)\n",
    "\n",
    "        print([len(x) for x in tm_chunks])\n",
    "\n",
    "        chunker.resize_chunks(int(chunker._adjusted_chunk_size * 4))\n",
    "\n",
    "        tm = TopicModeler(\n",
    "            chunks=[Document(page_content=doc) for doc in tm_chunks], \n",
    "            speed='learn', \n",
    "            workers=8\n",
    "        )\n",
    "        topic_words, _, topic_nums = tm.get_topics(1)\n",
    "\n",
    "        for words, tid in zip(topic_words, topic_nums):\n",
    "            print(f'Topic: ' + ' '.join(words))\n",
    "\n",
    "        topics_string = ' '.join(words)\n",
    "        top_results, _ = retriever.search(topics_string, 3)\n",
    "\n",
    "        for result in top_results:\n",
    "            print(f'found definition: {result}')\n",
    "\n",
    "        chunks.insert(0, 'context: ' + ', '.join(top_results))\n",
    "        chunk_summaries = [pipeline.summarize(c) for c in chunks]\n",
    "        combined = \" \".join(chunk_summaries)\n",
    "\n",
    "        # If combined summary is too long, iteratively re-chunk and re-summarize\n",
    "        max_rounds = 5\n",
    "        for _ in range(max_rounds):\n",
    "            tokens = tokenizer(combined, return_tensors='pt', truncation=False)['input_ids']\n",
    "            if tokens.shape[1] <= min(1024, pipeline.model_max_length):\n",
    "                break\n",
    "            re_chunks = chunker.chunk_text(combined)\n",
    "            combined = \" \".join(pipeline.summarize(rc) for rc in re_chunks)\n",
    "\n",
    "        summaries.append(combined)\n",
    "\n",
    "    # Clean up GPU memory\n",
    "    del pipeline, model_config\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sting = ', '.join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sting.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CEO Jensen Huang and CFO Colette Kress speak. Nvidia expects Hopper to ship in large volumes in April quarter Analysts: Is there a deal in the works with Mercedes-Benz Analysts: Can you give us a sense of where gaming is at right now'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
