{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import asyncio\n",
    "import requests\n",
    "import subprocess\n",
    "import textstat\n",
    "import bert_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from rouge import Rouge\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "from llm_parser import DeepSeekAPI\n",
    "from io_functions import run, popen, load_if_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['ollama', 'serve']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_server_process = popen('ollama serve')\n",
    "\n",
    "ollama_server_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ollama version is 0.5.13'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ollama_version():\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ollama', '--version'], \n",
    "            check=True, \n",
    "            stdout=subprocess.PIPE, \n",
    "            stderr=subprocess.PIPE, \n",
    "            text=True\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except subprocess.CalledProcessError:\n",
    "        return 'Error while checking Ollama version.'\n",
    "\n",
    "get_ollama_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED    \n",
      "deepseek-r1:32b    38056bbcbb2d    19 GB     2 hours ago    \n",
      "deepseek-r1:8b     28f8fd6cdc67    4.9 GB    4 days ago     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = run('ollama list')\n",
    "\n",
    "print(process.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepseek-r1:32b', 'deepseek-r1:8b']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    line.strip() for line in process.stdout.split('\\n')\n",
    "        if line != ''\n",
    "][1:]\n",
    "\n",
    "model_list = [model.split()[0] for model in models]\n",
    "model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent running a non-existing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepseek-r1:32b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model_list[0]\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'deepseek-r1:32b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name not in model_list:\n",
    "    run(f'ollama pull {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model\n",
      "    architecture        qwen2     \n",
      "    parameters          32.8B     \n",
      "    context length      131072    \n",
      "    embedding length    5120      \n",
      "    quantization        Q4_K_M    \n",
      "\n",
      "  Parameters\n",
      "    stop    \"<｜begin▁of▁sentence｜>\"    \n",
      "    stop    \"<｜end▁of▁sentence｜>\"      \n",
      "    stop    \"<｜User｜>\"                 \n",
      "    stop    \"<｜Assistant｜>\"            \n",
      "\n",
      "  License\n",
      "    MIT License                    \n",
      "    Copyright (c) 2023 DeepSeek    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run(f'ollama show {model_name}').stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_length': 5120, 'context_length': 131072}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_model_info(text: str):\n",
    "    embedding_match = re.search(r'embedding length\\s+(\\d+)', text)\n",
    "    context_match = re.search(r'context length\\s+(\\d+)', text)\n",
    "    \n",
    "    embedding_length = int(embedding_match.group(1)) if embedding_match else None\n",
    "    context_length = int(context_match.group(1)) if context_match else None\n",
    "    \n",
    "    return {\n",
    "        'embedding_length': embedding_length,\n",
    "        'context_length': context_length\n",
    "    }\n",
    "\n",
    "model_info = extract_model_info(run(f'ollama show {model_name}').stdout)\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process = popen(f'ollama run {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME    ID    SIZE    PROCESSOR    UNTIL \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run('ollama ps').stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_id = '312932093'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:successfully loaded local transcripts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>mostimportanttimeutc</th>\n",
       "      <th>headline</th>\n",
       "      <th>full_text</th>\n",
       "      <th>uuid</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312932093</td>\n",
       "      <td>Google LLC</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>Google LLC Presents at The 14th annual Red Hat...</td>\n",
       "      <td>Attendees: Now if there's a company that under...</td>\n",
       "      <td>123c9e75-b8dc-40b1-b21c-ffc9e71e01c6</td>\n",
       "      <td>12407</td>\n",
       "      <td>14475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312932093</td>\n",
       "      <td>Google LLC</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>Google LLC, Squarespace, Inc. - M&amp;A Call</td>\n",
       "      <td>Operator: Good afternoon. My name is Sara, and...</td>\n",
       "      <td>123c9e75-b8dc-40b1-b21c-ffc9e71e01c6</td>\n",
       "      <td>10078</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   companyid companyname mostimportantdateutc mostimportanttimeutc  \\\n",
       "0  312932093  Google LLC           2018-05-10             15:30:00   \n",
       "1  312932093  Google LLC           2023-06-15             21:00:00   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Google LLC Presents at The 14th annual Red Hat...   \n",
       "1           Google LLC, Squarespace, Inc. - M&A Call   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Attendees: Now if there's a company that under...   \n",
       "1  Operator: Good afternoon. My name is Sara, and...   \n",
       "\n",
       "                                   uuid  word_count  word_count_nltk  \n",
       "0  123c9e75-b8dc-40b1-b21c-ffc9e71e01c6       12407            14475  \n",
       "1  123c9e75-b8dc-40b1-b21c-ffc9e71e01c6       10078            11800  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_if_scraped(company_id=company_id)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeekAPI(model_name=deepseek-r1:32b, url=http://localhost:11434/api/generate, stream=False, timeout=30, max_retries=3)\n"
     ]
    }
   ],
   "source": [
    "api = DeepSeekAPI(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8781f70b834d69aa3026a3d041670a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'DeepSeekAPI' has no attribute 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m summaries\n\u001b[1;32m     15\u001b[0m \u001b[39m# Now you can use await directly\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m summaries \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m batch_summary_generation(api, df\u001b[39m.\u001b[39mfull_text)\n",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m, in \u001b[0;36mbatch_summary_generation\u001b[0;34m(api, texts)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m tqdm(texts):\n\u001b[1;32m     10\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msummarize: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m text\n\u001b[0;32m---> 11\u001b[0m     summary \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m api\u001b[39m.\u001b[39mgenerate(prompt\u001b[39m=\u001b[39mprompt)\n\u001b[1;32m     12\u001b[0m     summaries\u001b[39m.\u001b[39mappend(summary)\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m summaries\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:189\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    188\u001b[0m async_wrapped\u001b[39m.\u001b[39mstatistics \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mstatistics  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m copy(fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:111\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter(retry_state\u001b[39m=\u001b[39mretry_state)\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_state\u001b[39m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs: typing\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: typing\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mreturn\u001b[39;00m call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_post_retry_check_actions\u001b[39m(\u001b[39mself\u001b[39m, retry_state: \u001b[39m\"\u001b[39m\u001b[39mRetryCallState\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_state\u001b[39m.\u001b[39mis_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_state\u001b[39m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_action_func(\u001b[39mlambda\u001b[39;00m rs: rs\u001b[39m.\u001b[39;49moutcome\u001b[39m.\u001b[39;49mresult())\n\u001b[1;32m    399\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:114\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/persistent/ragsum/utils/llm_parser.py:73\u001b[0m, in \u001b[0;36mDeepSeekAPI.generate\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m aiohttp\u001b[39m.\u001b[39mClientSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m     72\u001b[0m         request_data \u001b[39m=\u001b[39m {\n\u001b[0;32m---> 73\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name, \n\u001b[1;32m     74\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m: prompt, \n\u001b[1;32m     75\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream\n\u001b[1;32m     76\u001b[0m         }\n\u001b[1;32m     77\u001b[0m         logging\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSending request to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m with model \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_non_streaming(session, request_data)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'DeepSeekAPI' has no attribute 'model_name'"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def batch_summary_generation(api: DeepSeekAPI, texts) -> list[str]:\n",
    "    summaries = []\n",
    "    for text in tqdm(texts):\n",
    "        prompt = 'summarize: ' + text\n",
    "        summary = await api.generate(prompt=prompt)\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "# Now you can use await directly\n",
    "summaries = await batch_summary_generation(api, df.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_column = f'{model_name}-summaries'\n",
    "df[summary_column] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summary(row, model_name, type = 'baseline'):\n",
    "    text_to_summarize = row.full_text\n",
    "    summary = row[summary_column]\n",
    "    uuid = row.uuid\n",
    "    company_id = row.companyid\n",
    "    company_name = row.companyname\n",
    "\n",
    "    rouge_evaluator = Rouge()\n",
    "    rouge_scores = rouge_evaluator.get_scores(summary, text_to_summarize)\n",
    "    \n",
    "    if isinstance(rouge_scores, list):\n",
    "        rouge_scores = rouge_scores[0]\n",
    "    \n",
    "    reference_tokens = text_to_summarize.split()\n",
    "    candidate_tokens = summary.split()\n",
    "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens)\n",
    "    \n",
    "    P, R, F1 = bert_score.score(\n",
    "        [summary], \n",
    "        [text_to_summarize], \n",
    "        rescale_with_baseline=True, \n",
    "        lang='en'\n",
    "    )\n",
    "    \n",
    "    original_len = len(text_to_summarize.split())\n",
    "    summary_len = len(summary.split())\n",
    "    compression_ratio = summary_len / original_len if original_len > 0 else 0\n",
    "    \n",
    "    readability = textstat.flesch_reading_ease(summary)\n",
    "    \n",
    "    results = {}\n",
    "    results['model_name'] = model_name\n",
    "    results['uuid'] = uuid\n",
    "    results['companyid'] = company_id\n",
    "    results['companyname'] = company_name\n",
    "\n",
    "    for metric, scores in rouge_scores.items():\n",
    "        results[f'{metric}_r'] = scores['r']\n",
    "        results[f'{metric}_p'] = scores['p']\n",
    "        results[f'{metric}_f'] = scores['f']\n",
    "    \n",
    "    results['bleu'] = bleu_score\n",
    "    results['bert_precision'] = P.item()\n",
    "    results['bert_recall'] = R.item()\n",
    "    results['bert_f1'] = F1.item()\n",
    "    results['compression_ratio'] = compression_ratio\n",
    "    results['readability'] = readability\n",
    "    \n",
    "    return pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = pd.DataFrame()\n",
    "\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    evaluation_result = evaluate_summary(row, model_name)\n",
    "    evaluation_results = pd.concat([evaluation_results, evaluation_result], ignore_index=True)\n",
    "\n",
    "evaluation_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = Path('..') / 'data' / 'evaluation_results.csv'\n",
    "\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    if ((existing_df.model_name == model_name) & (existing_df.companyid == company_id)).any():\n",
    "        logging.info(f'model {model_name} and {company_id} combination already exists in {csv_filename}. no new row added.')\n",
    "        updated_df = existing_df\n",
    "    else:\n",
    "        updated_df = pd.concat([existing_df, evaluation_results], ignore_index=True)\n",
    "        logging.info(f'model {model_name} not found. appending new row to {csv_filename}.')\n",
    "else:\n",
    "    updated_df = evaluation_results\n",
    "    logging.info(f'{csv_filename} not found. creating new file.')\n",
    "\n",
    "updated_df.to_csv(csv_filename, index=False)\n",
    "logging.info(f'results saved to {csv_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(df):\n",
    "    '''\n",
    "    Visualizes evaluation metrics stored in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing evaluation results with numeric metric columns.\n",
    "    \n",
    "    This function produces:\n",
    "    - Histograms for each numeric metric.\n",
    "    - A correlation heatmap of the numeric metrics.\n",
    "    '''\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    \n",
    "    df[numeric_cols].hist(bins=20, figsize=(15, 10))\n",
    "    plt.suptitle('Histograms of Evaluation Metrics', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Heatmap of Evaluation Metrics', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "visualize_results(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "        Path('..') / 'data' / 'summaries' / f'{company_id}_{model_name}.csv'.replace('/','-'),\n",
    "        sep='\\t',\n",
    "        index=False,\n",
    "        quoting=1,\n",
    "        escapechar='\\\\',\n",
    "        doublequote=True,\n",
    "        quotechar='\"',\n",
    "        lineterminator='\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.full_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[summary_column][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_process.terminate()\n",
    "ollama_server_process.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
